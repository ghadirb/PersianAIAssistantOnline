package com.persianai.assistant.services

import android.content.Context
import android.media.MediaRecorder
import android.os.Build
import android.util.Log
import kotlinx.coroutines.*
import okhttp3.MediaType.Companion.toMediaType
import okhttp3.OkHttpClient
import okhttp3.Request
import okhttp3.RequestBody.Companion.toRequestBody
import org.json.JSONObject
import java.io.File
import kotlin.math.min

/**
 * Ø³ÛŒØ³ØªÙ… Ø¶Ø¨Ø· ØµØ¯Ø§ÛŒ ØªØ±Ú©ÛŒØ¨ÛŒ (Offline + Online)
 * - Offline: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Haaniye Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ÙÙˆØ±ÛŒ
 * - Online: Ø¢Ù¾Ù„ÙˆØ¯ Ø¨Ù‡ Ø³Ø±ÙˆØ±Ù‡Ø§ÛŒ aimlapi ÛŒØ§ Qwen2.5 Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡
 */
class HybridVoiceRecorder(
    private val context: Context,
    private val coroutineScope: CoroutineScope = CoroutineScope(Dispatchers.Main + Job())
) {
    
    private val TAG = "HybridVoiceRecorder"
    private var mediaRecorder: MediaRecorder? = null
    private var audioFile: File? = null
    private var isRecording = false
    private var recordingStartTime = 0L
    private var listener: RecorderListener? = null
    
    interface RecorderListener {
        fun onRecordingStarted()
        fun onRecordingCompleted(audioFile: File, durationMs: Long)
        fun onRecordingCancelled()
        fun onRecordingError(error: String)
        fun onAmplitudeChanged(amplitude: Int)
    }
    
    /**
     * Ø´Ø±ÙˆØ¹ Ø¶Ø¨Ø· ØµØ¯Ø§ Ø¨Ø§ Ù…Ø­Ø§ÙØ¸Øª Ú©Ø§Ù…Ù„ÛŒ
     */
    fun startRecording() {
        try {
            if (isRecording) {
                Log.w(TAG, "âš ï¸ Recording already in progress")
                return
            }
            
            // Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ
            val audioDir = File(context.cacheDir, "hybrid_voice")
            if (!audioDir.exists()) {
                audioDir.mkdirs()
            }
            
            // Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯
            audioFile = File(audioDir, "recording_${System.currentTimeMillis()}.m4a")
            
            // ØªÙ†Ø¸ÛŒÙ… MediaRecorder
            mediaRecorder = if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.S) {
                MediaRecorder(context)
            } else {
                @Suppress("DEPRECATION")
                MediaRecorder()
            }.apply {
                try {
                    setAudioSource(MediaRecorder.AudioSource.MIC)
                    setOutputFormat(MediaRecorder.OutputFormat.MPEG_4)
                    setAudioEncoder(MediaRecorder.AudioEncoder.AAC)
                    setAudioEncodingBitRate(192000) // Ø¨ÛŒØ´ØªØ± Ø¨Ø±Ø§ÛŒ Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§
                    setAudioSamplingRate(44100)
                    setOutputFile(audioFile?.absolutePath)
                    
                    prepare()
                    start()
                    
                    Log.d(TAG, "âœ… Recording started: ${audioFile?.absolutePath}")
                } catch (e: Exception) {
                    Log.e(TAG, "âŒ Error preparing recorder", e)
                    throw e
                }
            }
            
            recordingStartTime = System.currentTimeMillis()
            isRecording = true
            listener?.onRecordingStarted()
            
            // Ø´Ø±ÙˆØ¹ Amplitude Monitoring
            startAmplitudeMonitoring()
            
        } catch (e: Exception) {
            Log.e(TAG, "âŒ Error starting recording", e)
            cleanup()
            listener?.onRecordingError("Ø®Ø·Ø§ Ø¯Ø± Ø´Ø±ÙˆØ¹ Ø¶Ø¨Ø·: ${e.message}")
        }
    }
    
    /**
     * ØªÙˆÙ‚Ù Ø¶Ø¨Ø· Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµØ¯Ø§
     */
    fun stopRecording() {
        try {
            if (!isRecording) {
                Log.w(TAG, "âš ï¸ No recording in progress")
                return
            }
            
            mediaRecorder?.apply {
                try {
                    stop()
                    release()
                } catch (e: Exception) {
                    Log.e(TAG, "âš ï¸ Error stopping recorder", e)
                }
            }
            mediaRecorder = null
            isRecording = false
            
            val duration = System.currentTimeMillis() - recordingStartTime
            
            audioFile?.let { file ->
                if (file.exists() && file.length() > 0) {
                    Log.d(TAG, "âœ… Recording completed: ${file.absolutePath} (${file.length()} bytes)")
                    listener?.onRecordingCompleted(file, duration)
                } else {
                    Log.w(TAG, "âš ï¸ Audio file is empty")
                    listener?.onRecordingError("ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª")
                }
            }
            
        } catch (e: Exception) {
            Log.e(TAG, "âŒ Error stopping recording", e)
            listener?.onRecordingError("Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ‚Ù Ø¶Ø¨Ø·: ${e.message}")
        }
    }
    
    /**
     * Ù„ØºÙˆ Ø¶Ø¨Ø· Ùˆ Ø­Ø°Ù ÙØ§ÛŒÙ„
     */
    fun cancelRecording() {
        try {
            if (!isRecording) return
            
            mediaRecorder?.apply {
                try {
                    stop()
                    release()
                } catch (e: Exception) {
                    Log.e(TAG, "âš ï¸ Error during cancel", e)
                }
            }
            mediaRecorder = null
            
            // Ø­Ø°Ù ÙØ§ÛŒÙ„
            audioFile?.delete()
            audioFile = null
            
            isRecording = false
            Log.d(TAG, "âœ… Recording cancelled")
            listener?.onRecordingCancelled()
            
        } catch (e: Exception) {
            Log.e(TAG, "âŒ Error cancelling recording", e)
            cleanup()
        }
    }
    
    /**
     * Ù†Ø¸Ø§Ø±Øª Ø¨Ø± Amplitude (Ø´Ø¯Øª ØµØ¯Ø§)
     */
    private fun startAmplitudeMonitoring() {
        coroutineScope.launch {
            while (isRecording) {
                try {
                    mediaRecorder?.maxAmplitude?.let { amplitude ->
                        listener?.onAmplitudeChanged(amplitude)
                    }
                    delay(100) // Ù‡Ø± 100ms
                } catch (e: Exception) {
                    Log.e(TAG, "âš ï¸ Error monitoring amplitude", e)
                }
            }
        }
    }
    
    /**
     * ØªØ­Ù„ÛŒÙ„ Offline (Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Haaniye)
     */
    suspend fun analyzeOffline(audioFile: File): String? = withContext(Dispatchers.IO) {
        return@withContext try {
            Log.d(TAG, "ğŸ” Analyzing with offline model (Haaniye)...")
            
            // Check if audio file exists
            if (!audioFile.exists() || audioFile.length() == 0L) {
                Log.w(TAG, "âš ï¸ Audio file doesn't exist or is empty")
                return@withContext null
            }
            
            // For now, return placeholder text
            // In production, implement Haaniye model loading here
            "ØªØ­Ù„ÛŒÙ„ Ø¢ÙÙ„Ø§ÛŒÙ†: ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯ (${audioFile.length()} Ø¨Ø§ÛŒØª)"
            
        } catch (e: Exception) {
            Log.e(TAG, "âŒ Error in offline analysis", e)
            null
        }
    }
    
    /**
     * ØªØ­Ù„ÛŒÙ„ Online (aimlapi / Qwen2.5)
     */
    suspend fun analyzeOnline(audioFile: File): String? = withContext(Dispatchers.IO) {
        return@withContext try {
            Log.d(TAG, "ğŸŒ Uploading to online model...")
            
            // Check if audio file exists
            if (!audioFile.exists() || audioFile.length() == 0L) {
                Log.w(TAG, "âš ï¸ Audio file doesn't exist or is empty")
                return@withContext null
            }
            
            val httpClient = OkHttpClient()
            
            // Try using aimlapi for speech recognition
            val apiKey = "your-aimlapi-key" // TODO: Get from preferences
            if (apiKey.isBlank() || apiKey == "your-aimlapi-key") {
                Log.d(TAG, "âš ï¸ API key not configured, returning placeholder")
                return@withContext "ØªØ­Ù„ÛŒÙ„ Ø¢Ù†Ù„Ø§ÛŒÙ†: Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ Ú©Ù„ÛŒØ¯ API"
            }
            
            // Upload audio file to aimlapi
            val audioBytes = audioFile.readBytes()
            val body = audioBytes.toRequestBody("audio/m4a".toMediaType())
            
            val request = Request.Builder()
                .url("https://api.aimlapi.com/v1/audio/transcribe")
                .addHeader("Authorization", "Bearer $apiKey")
                .post(body)
                .build()
            
            httpClient.newCall(request).execute().use { response ->
                if (!response.isSuccessful) {
                    Log.e(TAG, "âŒ API Error: ${response.code} ${response.message}")
                    return@use "Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø¢Ù†Ù„Ø§ÛŒÙ†"
                }
                
                val responseBody = response.body?.string() ?: return@use "Ù¾Ø§Ø³Ø® Ø®Ø§Ù„ÛŒ"
                
                // Parse JSON response
                try {
                    val json = JSONObject(responseBody)
                    val text = json.optString("result", json.optString("text", responseBody))
                    Log.d(TAG, "âœ… Online analysis result: $text")
                    text
                } catch (e: Exception) {
                    Log.d(TAG, "âš ï¸ Could not parse JSON, returning raw response")
                    responseBody
                }
            }
            
        } catch (e: Exception) {
            Log.e(TAG, "âŒ Error in online analysis", e)
            null
        }
    }
    
    /**
     * ØªØ­Ù„ÛŒÙ„ ØªØ±Ú©ÛŒØ¨ÛŒ (Offline Ø³Ù¾Ø³ Online)
     */
    suspend fun analyzeHybrid(audioFile: File): String? = withContext(Dispatchers.IO) {
        return@withContext try {
            Log.d(TAG, "âš¡ Starting hybrid analysis...")
            
            // Step 1: Offline analysis
            val offlineResult = analyzeOffline(audioFile)
            Log.d(TAG, "âœ… Offline analysis done: $offlineResult")
            
            // Step 2: Parallel online analysis
            val onlineResult = async { analyzeOnline(audioFile) }.await()
            Log.d(TAG, "âœ… Online analysis done: $onlineResult")
            
            // Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¨Ù‡ØªØ±ÛŒÙ† Ù†ØªÛŒØ¬Ù‡
            offlineResult ?: onlineResult
        } catch (e: Exception) {
            Log.e(TAG, "âŒ Error in hybrid analysis", e)
            null
        }
    }
    
    /**
     * Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù…Ù†Ø§Ø¨Ø¹
     */
    private fun cleanup() {
        try {
            mediaRecorder?.apply {
                try {
                    stop()
                } catch (e: Exception) {
                    // Ignore
                }
                try {
                    release()
                } catch (e: Exception) {
                    // Ignore
                }
            }
        } catch (e: Exception) {
            // Ignore
        } finally {
            mediaRecorder = null
            isRecording = false
            audioFile = null
        }
    }
    
    fun setListener(listener: RecorderListener) {
        this.listener = listener
    }
    
    fun isRecordingInProgress(): Boolean = isRecording
    
    fun getCurrentRecordingDuration(): Long {
        return if (isRecording) {
            System.currentTimeMillis() - recordingStartTime
        } else {
            0
        }
    }
    
    fun getRecordingFile(): File? = audioFile
    
    override fun finalize() {
        try {
            cleanup()
        } catch (e: Exception) {
            Log.e(TAG, "Error in finalize", e)
        }
    }
}
