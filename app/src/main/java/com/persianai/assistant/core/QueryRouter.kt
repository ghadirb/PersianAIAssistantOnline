package com.persianai.assistant.core

import android.content.Context
import android.util.Log
import com.persianai.assistant.ai.AIClient
import com.persianai.assistant.models.AIModel
import com.persianai.assistant.models.AIProvider
import com.persianai.assistant.models.ChatMessage
import com.persianai.assistant.models.MessageRole
import com.persianai.assistant.utils.PreferencesManager
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.withContext

/**
 * Ù…Ø±Ú©Ø²ÛŒ Query Router
 * ÛØ± query Ú©Ùˆ ØµØ­ÛŒØ­ Ø¬Ú¯Û Ø±ÙˆÙ¹ Ú©Ø±ØªØ§ ÛÛ’:
 * 1. Action Executor (Ø§Ú¯Ø± pattern match ÛÙˆ)
 * 2. Online Model (Ø§Ú¯Ø± Ø¢Ù†Ù„Ø§ÛŒÙ† Ø¯Ø³ØªÛŒØ§Ø¨ ÛÙˆ)
 * 3. Offline Model (fallback)
 */
class QueryRouter(private val context: Context) {
    
    private val TAG = "QueryRouter"
    private val actionExecutor = ActionExecutor(context)
    private val intentController = AIIntentController(context)
    private val prefs = PreferencesManager(context)
    
    suspend fun routeQuery(query: String): QueryResult = withContext(Dispatchers.IO) {
        try {
            Log.d(TAG, "ğŸš€ Routing query: $query")
            
            // Step 1: Try Action Execution
            Log.d(TAG, "1ï¸âƒ£ Checking for executable actions...")
            val actionResult = actionExecutor.executeFromQuery(query)
            if (actionResult.success && actionResult.action != null) {
                Log.d(TAG, "âœ… Action executed: ${actionResult.action}")
                return@withContext QueryResult(
                    success = true,
                    response = actionResult.message,
                    source = "action",
                    actionExecuted = true,
                    model = null
                )
            }
            
            // Step 2: Try Online Model (only path)
            Log.d(TAG, "2ï¸âƒ£ Checking for online model...")
            val onlineResult = tryOnlineModel(query)
            if (onlineResult != null) {
                Log.d(TAG, "âœ… Online model responded: ${onlineResult.model}")
                return@withContext QueryResult(
                    success = true,
                    response = onlineResult.response,
                    source = "online",
                    actionExecuted = false,
                    model = onlineResult.model
                )
            }
            
            // Step 3: All failed (no offline fallback)
            Log.w(TAG, "âŒ Online model failed")
            return@withContext QueryResult(
                success = false,
                response = "Ù…Ø¹Ø§ÙÛŒ Ú†Ø§ÛØªØ§ ÛÙˆÚºØŒ Ú©ÙˆØ¦ÛŒ Ø¨Ú¾ÛŒ Ø·Ø±ÛŒÙ‚Û Ú©Ø§Ù… Ù†Û Ú©Ø± Ø³Ú©Ø§Û” Ø¨Ø±Ø§Û Ù…ÛØ±Ø¨Ø§Ù†ÛŒ Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚºÛ”",
                source = "none",
                actionExecuted = false,
                model = null
            )
        } catch (e: Exception) {
            Log.e(TAG, "âŒ Router error: ${e.message}", e)
            QueryResult(
                success = false,
                response = "Ø®Ø·Ø§: ${e.message}",
                source = "error",
                actionExecuted = false,
                model = null,
                exception = e
            )
        }
    }
    
    /**
     * Ø¢Ù†Ù„Ø§ÛŒÙ† Ù…Ø§ÚˆÙ„ Ú©Ùˆ try Ú©Ø±ÛŒÚº
     */
    private suspend fun tryOnlineModel(query: String): OnlineResult? {
        return try {
            val apiKeys = prefs.getAPIKeys()
            val activeKeys = apiKeys.filter { it.isActive && !it.key.isNullOrBlank() }
            
            if (activeKeys.isEmpty()) {
                Log.w(TAG, "âš ï¸ No active API keys")
                return null
            }
            
            Log.d(TAG, "ğŸ“Š Available providers: ${activeKeys.map { it.provider.name }}")

            // Ø§ÙˆÙ„ÙˆÛŒØª: OpenAI GPT-4o-mini Ø³Ù¾Ø³ Avalai Gemini-2.5-Flash
            val candidates = mutableListOf<AIModel>()
            if (activeKeys.any { it.provider == AIProvider.OPENAI }) {
                candidates.add(AIModel.GPT_4O_MINI)
            }
            if (activeKeys.any { it.provider == AIProvider.AVALAI }) {
                candidates.add(AIModel.AVALAI_GEMINI_FLASH)
            }
            if (candidates.isEmpty()) {
                Log.w(TAG, "âš ï¸ No OpenAI/Avalai key active; skipping online chat")
                return null
            }

            val aiClient = AIClient(activeKeys)
            val messages = listOf(ChatMessage(role = MessageRole.USER, content = query))

            for (model in candidates) {
                try {
                    Log.d(TAG, "ğŸŒ Trying online model: ${model.displayName}")
                    val response = aiClient.sendMessage(model, messages)
                    Log.d(TAG, "âœ… Got online response from ${model.displayName}")
                    return OnlineResult(response.content, model.displayName)
                } catch (e: Exception) {
                    Log.w(TAG, "âš ï¸ ${model.displayName} failed: ${e.message}")
                    continue
                }
            }

            Log.e(TAG, "âŒ All online providers failed in fallback chain")
            null
        } catch (e: Exception) {
            Log.w(TAG, "âš ï¸ Online model failed: ${e.message}")
            null
        }
    }
}

/**
 * Query Ú©Ø§ Ù†ØªÛŒØ¬Û
 */
data class QueryResult(
    val success: Boolean,
    val response: String,
    val source: String, // "action", "online", "offline", "none", "error"
    val actionExecuted: Boolean = false,
    val model: String? = null,
    val exception: Exception? = null
)

/**
 * Ø¢Ù†Ù„Ø§ÛŒÙ† Ù…Ø§ÚˆÙ„ Ú©Ø§ Ù†ØªÛŒØ¬Û
 */
data class OnlineResult(
    val response: String,
    val model: String
)

/**
 * Ø¢ÙÙ„Ø§ÛŒÙ† Ù…Ø§ÚˆÙ„ Ú©Ø§ Ù†ØªÛŒØ¬Û
 */
data class OfflineResult(
    val response: String,
    val model: String
)
