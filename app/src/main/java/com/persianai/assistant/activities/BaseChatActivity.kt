package com.persianai.assistant.activities

import android.Manifest
import android.content.Context.MODE_PRIVATE
import android.content.Intent
import android.content.pm.PackageManager
import android.os.Bundle
import android.speech.RecognizerIntent
import android.speech.SpeechRecognizer
import android.view.View
import android.widget.Toast
import androidx.appcompat.app.AppCompatActivity
import androidx.core.app.ActivityCompat
import androidx.core.content.ContextCompat
import androidx.lifecycle.lifecycleScope
import androidx.recyclerview.widget.LinearLayoutManager
import androidx.viewbinding.ViewBinding
import com.persianai.assistant.adapters.ChatAdapter
import com.persianai.assistant.ai.AIClient
import com.persianai.assistant.models.AIModel
import com.persianai.assistant.models.AIProvider
import com.persianai.assistant.models.APIKey
import com.persianai.assistant.models.ChatMessage
import com.persianai.assistant.models.Conversation
import com.persianai.assistant.models.MessageRole
import com.persianai.assistant.ui.VoiceRecorderView
import com.persianai.assistant.utils.DefaultApiKeys
import com.persianai.assistant.utils.PreferencesManager
import com.persianai.assistant.utils.TTSHelper
import com.persianai.assistant.utils.PreferencesManager.ProviderPreference
import com.persianai.assistant.services.VoiceRecordingHelper
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.launch
import kotlinx.coroutines.withContext
import android.util.Log
import okhttp3.MediaType.Companion.toMediaType
import okhttp3.OkHttpClient
import okhttp3.Request
import okhttp3.RequestBody.Companion.toRequestBody
import org.json.JSONObject
import java.io.File

abstract class BaseChatActivity : AppCompatActivity() {

    protected lateinit var binding: ViewBinding
    protected lateinit var chatAdapter: ChatAdapter
    protected lateinit var prefsManager: PreferencesManager
    protected lateinit var ttsHelper: TTSHelper
    protected var aiClient: AIClient? = null
    protected var currentModel: AIModel = AIModel.TINY_LLAMA_OFFLINE
    protected val messages = mutableListOf<ChatMessage>()
    private lateinit var speechRecognizer: SpeechRecognizer
    private var voiceRecorderView: VoiceRecorderView? = null
    protected lateinit var voiceHelper: VoiceRecordingHelper
    private lateinit var conversationStorage: com.persianai.assistant.storage.ConversationStorage
    private lateinit var currentConversation: Conversation
    private val httpClient = OkHttpClient()
    private val hfApiKey: String by lazy {
        getSharedPreferences("api_keys", MODE_PRIVATE)
            .getString("hf_api_key", null)
            ?.takeIf { it.isNotBlank() }
            ?: DefaultApiKeys.getHuggingFaceKey()
            ?: ""
    }

    companion object {
        private const val REQUEST_RECORD_AUDIO = 1001
    }

    private fun chooseBestModel(apiKeys: List<APIKey>, pref: ProviderPreference): AIModel {
        // Ø§ÙˆÙ„ÙˆÛŒØª Ø¢Ù†Ù„Ø§ÛŒÙ†: AIML â†’ OpenRouter (Qwen Ø³Ø¨Ú©) â†’ OpenAI â†’ Ø¯Ø± Ù†Ù‡Ø§ÛŒØª Ø¢ÙÙ„Ø§ÛŒÙ†
        val activeProviders = apiKeys.filter { it.isActive }.map { it.provider }.toSet()
        return when {
            activeProviders.contains(com.persianai.assistant.models.AIProvider.AIML) -> AIModel.AIML_GPT_35
            activeProviders.contains(com.persianai.assistant.models.AIProvider.OPENROUTER) -> AIModel.QWEN_2_5_1B5
            activeProviders.contains(com.persianai.assistant.models.AIProvider.OPENAI) -> AIModel.GPT_4O_MINI
            else -> AIModel.TINY_LLAMA_OFFLINE
        }
    }

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        prefsManager = PreferencesManager(this)
        ttsHelper = TTSHelper(this)
        ttsHelper.initialize()
        speechRecognizer = SpeechRecognizer.createSpeechRecognizer(this)
        // Initialize conversation storage and load current conversation (if any)
        conversationStorage = com.persianai.assistant.storage.ConversationStorage(this)
        currentConversation = Conversation()
        lifecycleScope.launch {
            try {
                val id = conversationStorage.getCurrentConversationId()
                val loaded = if (!id.isNullOrBlank()) conversationStorage.getConversation(id) else null
                if (loaded != null) {
                    currentConversation = loaded
                    messages.clear()
                    messages.addAll(loaded.messages)
                    if (this@BaseChatActivity::chatAdapter.isInitialized) {
                        chatAdapter.notifyDataSetChanged()
                    }
                } else {
                    conversationStorage.setCurrentConversationId(currentConversation.id)
                    conversationStorage.saveConversation(currentConversation)
                }
            } catch (e: Exception) {
                android.util.Log.w("BaseChatActivity", "Failed loading conversation: ${e.message}")
            }
        }
        
        // Setup Voice Recording Helper
        voiceHelper = VoiceRecordingHelper(this)
        setupVoiceRecording()
    }

    protected abstract fun getRecyclerView(): androidx.recyclerview.widget.RecyclerView
    protected abstract fun getMessageInput(): com.google.android.material.textfield.TextInputEditText
    protected abstract fun getSendButton(): View
    protected abstract fun getVoiceButton(): View

    protected open fun setupChatUI() {
        setupRecyclerView()
        setupListeners()
        setupAIClient()
    }

    private fun setupRecyclerView() {
        chatAdapter = ChatAdapter(messages)
        getRecyclerView().apply {
            layoutManager = LinearLayoutManager(this@BaseChatActivity).apply {
                stackFromEnd = true
            }
            adapter = chatAdapter
        }
    }

    private suspend fun transcribeWithHuggingFace(audioFile: File): String? = withContext(Dispatchers.IO) {
        if (hfApiKey.isBlank()) {
            Log.w("HF-STT", "HuggingFace key not set; skipping HF transcription")
            return@withContext null
        }
        return@withContext try {
            val bytes = audioFile.readBytes()
            val body = bytes.toRequestBody("audio/m4a".toMediaType())
            val request = Request.Builder()
                .url("https://api-inference.huggingface.co/models/openai/whisper-large-v3")
                .addHeader("Authorization", "Bearer $hfApiKey")
                .post(body)
                .build()
            httpClient.newCall(request).execute().use { resp ->
                if (!resp.isSuccessful) {
                    android.util.Log.e("HF-STT", "Failed: ${resp.code} ${resp.message}")
                    return@use null
                }
                val text = resp.body?.string()?.trim() ?: return@use null
                if (text.startsWith("{")) {
                    return@use try {
                        val json = org.json.JSONObject(text)
                        json.optString("text").ifBlank { json.optString("generated_text") }
                    } catch (_: Exception) {
                        text
                    }
                }
                text
            }
        } catch (e: Exception) {
            android.util.Log.e("HF-STT", "error: ${e.message}", e)
            null
        }
    }

    private fun setupAIClient() {
        val apiKeys = prefsManager.getAPIKeys()
        if (apiKeys.isNotEmpty()) {
            aiClient = AIClient(apiKeys)
            val resolved = chooseBestModel(apiKeys, prefsManager.getProviderPreference())
            currentModel = resolved
            prefsManager.saveSelectedModel(currentModel)
            // âœ… Ø§Ú¯Ø± Ú©Ù„ÛŒØ¯ API Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³ØªØŒ Ø­Ø§Ù„Øª Ø±Ø§ Ø¨Ù‡ ONLINE ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯
            prefsManager.setWorkingMode(PreferencesManager.WorkingMode.ONLINE)
            Log.d("BaseChatActivity", "âœ… Ø­Ø§Ù„Øª ONLINE ÙØ¹Ø§Ù„ Ø´Ø¯ (Ú©Ù„ÛŒØ¯ API ÛŒØ§ÙØª Ø´Ø¯)")
        } else {
            Toast.makeText(this, "âš ï¸ Ú©Ù„ÛŒØ¯ API ÛŒØ§ÙØª Ù†Ø´Ø¯ - Ø­Ø§Ù„Øª Ø¢ÙÙ„Ø§ÛŒÙ† ÙØ¹Ø§Ù„ Ø§Ø³Øª", Toast.LENGTH_LONG).show()
            prefsManager.setWorkingMode(PreferencesManager.WorkingMode.OFFLINE)
        }
    }

    private fun setupListeners() {
        getSendButton().setOnClickListener {
            sendMessage()
        }
        
        // ØªÙ†Ø¸ÛŒÙ… VoiceRecorderView ÛŒØ§ VoiceActionButton
        try {
            voiceRecorderView = getVoiceButton() as? VoiceRecorderView
            if (voiceRecorderView != null) {
                voiceRecorderView!!.setListener(object : VoiceRecorderView.VoiceRecorderListener {
                    override fun onRecordingStarted() {
                        checkAudioPermissionAndStartRecording()
                    }
                    
                    override fun onRecordingCompleted(audioFile: File, durationMs: Long) {
                        transcribeAudio(audioFile)
                    }
                    
                    override fun onRecordingCancelled() {
                        Toast.makeText(this@BaseChatActivity, "âŒ Ø¶Ø¨Ø· Ù„ØºÙˆ Ø´Ø¯", Toast.LENGTH_SHORT).show()
                    }
                    
                    override fun onAmplitudeChanged(amplitude: Int) {
                        // Ù†Ù…Ø§ÛŒØ´ Ø´Ø¯Øª ØµØ¯Ø§
                    }
                })
                android.util.Log.d("BaseChatActivity", "VoiceRecorderView initialized successfully")
            } else {
                android.util.Log.w("BaseChatActivity", "VoiceRecorderView not found, voice recording disabled")
            }
        } catch (e: Exception) {
            android.util.Log.e("BaseChatActivity", "Error initializing VoiceRecorderView", e)
        }

        // If a unified VoiceActionButton exists in the layout, wire it up so
        // chat activities automatically benefit from the unified recorder.
        try {
            val vab = findViewById<com.persianai.assistant.ui.VoiceActionButton?>(
                resources.getIdentifier("voiceActionButton", "id", packageName)
            )
            if (vab != null) {
                vab.setListener(object : com.persianai.assistant.ui.VoiceActionButton.Listener {
                    override fun onRecordingStarted() {
                        onVoiceRecordingStarted()
                    }

                    override fun onRecordingCompleted(audioFile: File, durationMs: Long) {
                        transcribeAudio(audioFile)
                    }

                    override fun onTranscript(text: String) {
                        try {
                            getMessageInput().setText(text)
                            sendMessage()
                        } catch (_: Exception) { }
                    }

                    override fun onRecordingError(error: String) {
                        onVoiceRecordingError(error)
                    }
                })
                android.util.Log.d("BaseChatActivity", "VoiceActionButton wired")
            }
        } catch (e: Exception) {
            android.util.Log.w("BaseChatActivity", "VoiceActionButton not present or wiring failed", e)
        }
    }

    protected fun sendMessage() {
        val text = getMessageInput().text.toString().trim()
        if (text.isEmpty()) return

        val userMessage = ChatMessage(role = MessageRole.USER, content = text, timestamp = System.currentTimeMillis())
        addMessage(userMessage)
        getMessageInput().text?.clear()

        getSendButton().isEnabled = false

        lifecycleScope.launch {
            try {
                val response = handleRequest(text)
                val aiMessage = ChatMessage(role = MessageRole.ASSISTANT, content = response, timestamp = System.currentTimeMillis())
                addMessage(aiMessage)
            } catch (e: Exception) {
                val errorMessage = ChatMessage(role = MessageRole.ASSISTANT, content = "âŒ Ø®Ø·Ø§: ${e.message}", timestamp = System.currentTimeMillis(), isError = true)
                addMessage(errorMessage)
            } finally {
                getSendButton().isEnabled = true
            }
        }
    }

    protected open suspend fun handleRequest(text: String): String = withContext(Dispatchers.IO) {
        val apiKeys = prefsManager.getAPIKeys()
        val hasValidKeys = apiKeys.isNotEmpty() && apiKeys.any { it.isActive }
        val onlinePreferred = shouldUseOnlinePriority()

        // Ø³ÛŒØ§Ø³Øª: Ø¨Ù‡ ØµÙˆØ±Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ù‡Ù…Ù‡ Ú†Øªâ€ŒÙ‡Ø§ Ø¢ÙÙ„Ø§ÛŒÙ† Ù‡Ø³ØªÙ†Ø¯Ø› ÙÙ‚Ø· Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§ÙˆØ±Ù‡ Ø¨Ø§ override
        // shouldUseOnlinePriority() Ø§Ø¬Ø§Ø²Ù‡ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø¯Ø§Ø±Ù†Ø¯.
        if (onlinePreferred) {
            if (hasValidKeys && aiClient != null) {
                // Ø³Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø§Ø¨ØªØ¯Ø§
                try {
                    val model = chooseBestModel(apiKeys, prefsManager.getProviderPreference())
                    currentModel = model
                    android.util.Log.d("BaseChatActivity", "ğŸ“¡ (Counseling) Ø³Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø¨Ø§ Ù…Ø¯Ù„: ${model.name}")
                    val response = aiClient!!.sendMessage(
                        model,
                        messages,
                        getSystemPrompt() + "\n\nÙ¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø±: " + text
                    )
                    android.util.Log.d("BaseChatActivity", "âœ… Ù¾Ø§Ø³Ø® Ø¢Ù†Ù„Ø§ÛŒÙ† Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯")
                    return@withContext response.content
                } catch (e: Exception) {
                    android.util.Log.w("BaseChatActivity", "âš ï¸ Ø¢Ù†Ù„Ø§ÛŒÙ† Ù†Ø§Ù…ÙˆÙÙ‚: ${e.message}")
                    // Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ø¢ÙÙ„Ø§ÛŒÙ†
                }
            } else {
                android.util.Log.w("BaseChatActivity", "âš ï¸ (Counseling) Ú©Ù„ÛŒØ¯/APIClient Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³ØªØ› Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ø¢ÙÙ„Ø§ÛŒÙ†")
            }
        }

        // Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¢ÙÙ„Ø§ÛŒÙ† (SimpleOfflineResponder ÛŒØ§ TinyLlama)
        android.util.Log.d("BaseChatActivity", "ğŸ“µ Ø­Ø§Ù„Øª Ø¢ÙÙ„Ø§ÛŒÙ† ÙØ¹Ø§Ù„")
        return@withContext offlineRespond(text)
    }

    private fun offlineRespond(text: String): String {
        // âœ… Ø§Ø¨ØªØ¯Ø§ SimpleOfflineResponder Ø±Ø§ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù† - Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ Native Library
        val simpleResponse = com.persianai.assistant.ai.SimpleOfflineResponder.respond(this, text)
        if (!simpleResponse.isNullOrBlank()) {
            Log.d("BaseChatActivity", "âœ… SimpleOfflineResponder returned response")
            return simpleResponse
        }
        
        // Ø§Ú¯Ø± SimpleOfflineResponder Ù†ØªÙˆØ§Ù†Ø³ØªØŒ Ù¾Ø§Ø³Ø® Ø³Ø§Ø¯Ù‡â€ŒØªØ±ÛŒ Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
        Log.d("BaseChatActivity", "âš ï¸ SimpleOfflineResponder did not respond, showing default offline message")
        
        return buildString {
            append("ğŸ“µ **Ø­Ø§Ù„Øª Ø¢ÙÙ„Ø§ÛŒÙ† ÙØ¹Ø§Ù„**\n\n")
            append("âš ï¸ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯:\n\n")
            append("1ï¸âƒ£ ÛŒÚ© Ú©Ù„ÛŒØ¯ API ØªÙ‡ÛŒÙ‡ Ú©Ù†ÛŒØ¯:\n")
            append("   â€¢ OpenAI: https://platform.openai.com/api-keys\n")
            append("   â€¢ OpenRouter: https://openrouter.ai\n")
            append("   â€¢ AIML API: https://aimlapi.com\n\n")
            append("2ï¸âƒ£ Ø¨Ù‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ø±Ùˆ (âš™ï¸) Ùˆ Ú©Ù„ÛŒØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†\n")
            append("3ï¸âƒ£ Ø³Ù¾Ø³ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù¾Ø±Ø³ÛŒØ¯\n\n")
            append("ğŸ’¡ **Ø³ÙˆØ§Ù„ Ø´Ù…Ø§:** $text")
        }
    }

    /**
     * ÛŒØ§ÙØªÙ† Ù…Ø³ÛŒØ± Ù…Ø¯Ù„ tinyllama Ø¯Ø§Ù†Ù„ÙˆØ¯â€ŒØ´Ø¯Ù‡ (Ø¯Ø³ØªÛŒ ÛŒØ§ Ø§Ø² Ø·Ø±ÛŒÙ‚ OfflineModelManager)
     */
    private fun findOfflineModelPath(): String? {
        return try {
            val manager = com.persianai.assistant.models.OfflineModelManager(this)
            val list = manager.getDownloadedModels()
            android.util.Log.d("BaseChatActivity", "findOfflineModelPath: found ${list.size} downloaded models")
            list.forEach { pair ->
                try {
                    android.util.Log.d("BaseChatActivity", "Model entry: ${pair.first.name} -> ${pair.second}")
                } catch (_: Exception) { }
            }
            // Ø§ÙˆÙ„ TinyLlama
            list.firstOrNull { it.first.name.contains("TinyLlama", ignoreCase = true) }?.second
                ?: list.firstOrNull()?.second
        } catch (e: Exception) {
            android.util.Log.w("BaseChatActivity", "findOfflineModelPath failed: ${e.message}", e)
            null
        }
    }

    protected open fun shouldUseOnlinePriority(): Boolean = false

    protected open fun getSystemPrompt(): String {
        return "Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯ ÙØ§Ø±Ø³ÛŒ Ù‡Ø³ØªÛŒØ¯."
    }

    protected fun addMessage(message: ChatMessage) {
        messages.add(message)
        chatAdapter.notifyItemInserted(messages.size - 1)
        getRecyclerView().smoothScrollToPosition(messages.size - 1)
        if (message.role == MessageRole.ASSISTANT && !message.isError) {
            ttsHelper.speak(message.content)
        }
        // Persist message into current conversation
        try {
            currentConversation.messages.add(message)
            lifecycleScope.launch {
                try {
                    conversationStorage.saveConversation(currentConversation)
                } catch (_: Exception) { }
            }
        } catch (_: Exception) { }
    }

    private fun checkAudioPermissionAndStartRecording() {
        val permissions = arrayOf(Manifest.permission.RECORD_AUDIO)
        val missingPermissions = permissions.filter {
            ContextCompat.checkSelfPermission(this, it) != PackageManager.PERMISSION_GRANTED
        }
        
        if (missingPermissions.isNotEmpty()) {
            ActivityCompat.requestPermissions(this, missingPermissions.toTypedArray(), REQUEST_RECORD_AUDIO)
        }
    }

    protected fun transcribeAudio(audioFile: File) {
        lifecycleScope.launch {
            try {
                val workingMode = prefsManager.getWorkingMode()
                
                // âœ… Ø³Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø¢Ù†Ù„Ø§ÛŒÙ† ÛŒØ§ HuggingFace
                val transcribedText = try {
                    aiClient?.transcribeAudio(audioFile.absolutePath)
                        ?.takeIf { !it.isNullOrBlank() }
                } catch (e: Exception) {
                    Log.e("BaseChatActivity", "AIClient transcription failed: ${e.message}")
                    null
                } ?: try {
                    transcribeWithHuggingFace(audioFile)
                } catch (e: Exception) {
                    Log.e("BaseChatActivity", "HuggingFace transcription failed: ${e.message}")
                    null
                }
                
                if (!transcribedText.isNullOrEmpty()) {
                    getMessageInput().setText(transcribedText)
                    Toast.makeText(this@BaseChatActivity, "âœ… ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† ØªØ¨Ø¯ÛŒÙ„ Ø´Ø¯: \"$transcribedText\"", Toast.LENGTH_SHORT).show()
                    sendMessage()
                    return@launch
                }
                
                // âŒ Ø§Ú¯Ø± ØªØ¨Ø¯ÛŒÙ„ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯
                if (workingMode == PreferencesManager.WorkingMode.OFFLINE) {
                    Toast.makeText(
                        this@BaseChatActivity, 
                        "âš ï¸ ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§ØªØµØ§Ù„ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø¯Ø§Ø±Ø¯.\n\nØ¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª:\n1. Ú©Ù„ÛŒØ¯ API ØªÙ†Ø¸ÛŒÙ… Ú©Ù†\n2. Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†",
                        Toast.LENGTH_LONG
                    ).show()
                } else {
                    Toast.makeText(
                        this@BaseChatActivity,
                        "âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.",
                        Toast.LENGTH_SHORT
                    ).show()
                }
            } catch (e: Exception) {
                Log.e("BaseChatActivity", "Transcription failed: ${e.message}", e)
                Toast.makeText(
                    this@BaseChatActivity,
                    "âŒ Ø®Ø·Ø§: ${e.message}",
                    Toast.LENGTH_SHORT
                ).show()
            }
        }
    }

    override fun onRequestPermissionsResult(requestCode: Int, permissions: Array<String>, grantResults: IntArray) {
        super.onRequestPermissionsResult(requestCode, permissions, grantResults)
        if (requestCode == REQUEST_RECORD_AUDIO) {
            if (grantResults.isEmpty() || grantResults.any { it != PackageManager.PERMISSION_GRANTED }) {
                Toast.makeText(this, "âš ï¸ Ù…Ø¬ÙˆØ² Ø¶Ø¨Ø· ØµÙˆØª Ù„Ø§Ø²Ù… Ø§Ø³Øª", Toast.LENGTH_SHORT).show()
            }
        }
    }

    override fun onDestroy() {
        super.onDestroy()
        ttsHelper.shutdown()
        speechRecognizer.destroy()
        voiceHelper.cancelRecording()
    }
    
    // ===== Voice Recording Setup =====
    
    protected open fun setupVoiceRecording() {
        voiceHelper.setListener(object : VoiceRecordingHelper.RecordingListener {
            override fun onRecordingStarted() {
                Log.d("BaseChatActivity", "Recording started")
                onVoiceRecordingStarted()
            }
            
            override fun onRecordingCompleted(audioFile: File, durationMs: Long) {
                Log.d("BaseChatActivity", "Recording completed: ${audioFile.absolutePath}, Duration: ${durationMs}ms")
                onVoiceRecordingCompleted(audioFile, durationMs)
            }
            
            override fun onRecordingCancelled() {
                Log.d("BaseChatActivity", "Recording cancelled")
                onVoiceRecordingCancelled()
            }
            
            override fun onRecordingError(error: String) {
                Log.e("BaseChatActivity", "Recording error: $error")
                onVoiceRecordingError(error)
            }
        })
    }
    
    protected open fun onVoiceRecordingStarted() {
        Log.d("BaseChatActivity", "Voice recording started")
    }
    
    protected open fun onVoiceRecordingCompleted(audioFile: File, durationMs: Long) {
        Log.d("BaseChatActivity", "Voice recording completed")
        // Ù¾Ø³ Ø§Ø² Ø§ØªÙ…Ø§Ù… Ø¶Ø¨Ø·: ØªØ¨Ø¯ÛŒÙ„ Ú¯ÙØªØ§Ø± Ø¨Ù‡ Ù…ØªÙ† Ùˆ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ Ú†Øª
        transcribeAudio(audioFile)
    }
    
    protected open fun onVoiceRecordingCancelled() {
        Log.d("BaseChatActivity", "Voice recording cancelled")
    }
    
    protected open fun onVoiceRecordingError(error: String) {
        Log.e("BaseChatActivity", "Voice recording error: $error")
        Toast.makeText(this, "Ø®Ø·Ø§: $error", Toast.LENGTH_SHORT).show()
    }
    
    protected fun startVoiceRecording() {
        if (ContextCompat.checkSelfPermission(this, Manifest.permission.RECORD_AUDIO)
            == PackageManager.PERMISSION_GRANTED
        ) {
            voiceHelper.startRecording()
        } else {
            ActivityCompat.requestPermissions(
                this,
                arrayOf(Manifest.permission.RECORD_AUDIO),
                REQUEST_RECORD_AUDIO
            )
        }
    }
    
    protected fun stopVoiceRecording() {
        voiceHelper.stopRecording()
    }
    
    protected fun cancelVoiceRecording() {
        voiceHelper.cancelRecording()
    }
}
