package com.persianai.assistant.activities

import android.Manifest
import android.content.Context.MODE_PRIVATE
import android.content.Intent
import android.content.pm.PackageManager
import android.os.Bundle
import android.speech.RecognizerIntent
import android.speech.SpeechRecognizer
import android.view.View
import android.widget.Toast
import androidx.appcompat.app.AppCompatActivity
import androidx.core.app.ActivityCompat
import androidx.core.content.ContextCompat
import androidx.lifecycle.lifecycleScope
import androidx.recyclerview.widget.LinearLayoutManager
import androidx.viewbinding.ViewBinding
import com.persianai.assistant.adapters.ChatAdapter
import com.persianai.assistant.ai.AIClient
import com.persianai.assistant.models.AIModel
import com.persianai.assistant.models.AIProvider
import com.persianai.assistant.models.APIKey
import com.persianai.assistant.models.ChatMessage
import com.persianai.assistant.models.MessageRole
import com.persianai.assistant.ui.VoiceRecorderView
import com.persianai.assistant.utils.DefaultApiKeys
import com.persianai.assistant.utils.PreferencesManager
import com.persianai.assistant.utils.TTSHelper
import com.persianai.assistant.utils.PreferencesManager.ProviderPreference
import com.persianai.assistant.services.VoiceRecordingHelper
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.launch
import kotlinx.coroutines.withContext
import android.util.Log
import okhttp3.MediaType.Companion.toMediaType
import okhttp3.OkHttpClient
import okhttp3.Request
import okhttp3.RequestBody.Companion.toRequestBody
import org.json.JSONObject
import java.io.File

abstract class BaseChatActivity : AppCompatActivity() {

    protected lateinit var binding: ViewBinding
    protected lateinit var chatAdapter: ChatAdapter
    protected lateinit var prefsManager: PreferencesManager
    protected lateinit var ttsHelper: TTSHelper
    protected var aiClient: AIClient? = null
    protected var currentModel: AIModel = AIModel.TINY_LLAMA_OFFLINE
    protected val messages = mutableListOf<ChatMessage>()
    private lateinit var speechRecognizer: SpeechRecognizer
    private var voiceRecorderView: VoiceRecorderView? = null
    protected lateinit var voiceHelper: VoiceRecordingHelper
    private val httpClient = OkHttpClient()
    private val hfApiKey: String by lazy {
        getSharedPreferences("api_keys", MODE_PRIVATE)
            .getString("hf_api_key", null)
            ?.takeIf { it.isNotBlank() }
            ?: DefaultApiKeys.getHuggingFaceKey()
            ?: ""
    }

    companion object {
        private const val REQUEST_RECORD_AUDIO = 1001
    }

    private fun chooseBestModel(apiKeys: List<APIKey>, pref: ProviderPreference): AIModel {
        // Ø§ÙˆÙ„ÙˆÛŒØª Ø¢Ù†Ù„Ø§ÛŒÙ†: AIML â†’ OpenRouter (Qwen Ø³Ø¨Ú©) â†’ OpenAI â†’ Ø¯Ø± Ù†Ù‡Ø§ÛŒØª Ø¢ÙÙ„Ø§ÛŒÙ†
        val activeProviders = apiKeys.filter { it.isActive }.map { it.provider }.toSet()
        return when {
            activeProviders.contains(com.persianai.assistant.models.AIProvider.AIML) -> AIModel.AIML_GPT_35
            activeProviders.contains(com.persianai.assistant.models.AIProvider.OPENROUTER) -> AIModel.QWEN_2_5_1B5
            activeProviders.contains(com.persianai.assistant.models.AIProvider.OPENAI) -> AIModel.GPT_4O_MINI
            else -> AIModel.TINY_LLAMA_OFFLINE
        }
    }

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        prefsManager = PreferencesManager(this)
        ttsHelper = TTSHelper(this)
        ttsHelper.initialize()
        speechRecognizer = SpeechRecognizer.createSpeechRecognizer(this)
        
        // Setup Voice Recording Helper
        voiceHelper = VoiceRecordingHelper(this)
        setupVoiceRecording()
    }

    protected abstract fun getRecyclerView(): androidx.recyclerview.widget.RecyclerView
    protected abstract fun getMessageInput(): com.google.android.material.textfield.TextInputEditText
    protected abstract fun getSendButton(): View
    protected abstract fun getVoiceButton(): View

    protected open fun setupChatUI() {
        setupRecyclerView()
        setupListeners()
        setupAIClient()
    }

    private fun setupRecyclerView() {
        chatAdapter = ChatAdapter(messages)
        getRecyclerView().apply {
            layoutManager = LinearLayoutManager(this@BaseChatActivity).apply {
                stackFromEnd = true
            }
            adapter = chatAdapter
        }
    }

    private suspend fun transcribeWithHuggingFace(audioFile: File): String? = withContext(Dispatchers.IO) {
        if (hfApiKey.isBlank()) {
            Log.w("HF-STT", "HuggingFace key not set; skipping HF transcription")
            return@withContext null
        }
        return@withContext try {
            val bytes = audioFile.readBytes()
            val body = bytes.toRequestBody("audio/m4a".toMediaType())
            val request = Request.Builder()
                .url("https://api-inference.huggingface.co/models/openai/whisper-large-v3")
                .addHeader("Authorization", "Bearer $hfApiKey")
                .post(body)
                .build()
            httpClient.newCall(request).execute().use { resp ->
                if (!resp.isSuccessful) {
                    android.util.Log.e("HF-STT", "Failed: ${resp.code} ${resp.message}")
                    return@use null
                }
                val text = resp.body?.string()?.trim() ?: return@use null
                if (text.startsWith("{")) {
                    return@use try {
                        val json = org.json.JSONObject(text)
                        json.optString("text").ifBlank { json.optString("generated_text") }
                    } catch (_: Exception) {
                        text
                    }
                }
                text
            }
        } catch (e: Exception) {
            android.util.Log.e("HF-STT", "error: ${e.message}", e)
            null
        }
    }

    private fun setupAIClient() {
        val apiKeys = prefsManager.getAPIKeys()
        if (apiKeys.isNotEmpty()) {
            aiClient = AIClient(apiKeys)
            val resolved = chooseBestModel(apiKeys, prefsManager.getProviderPreference())
            currentModel = resolved
            prefsManager.saveSelectedModel(currentModel)
        } else {
            Toast.makeText(this, "Ú©Ù„ÛŒØ¯ API Ø¢Ù†Ù„Ø§ÛŒÙ† ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ø­Ø§Ù„Øª Ø¢ÙÙ„Ø§ÛŒÙ† ÙØ¹Ø§Ù„ Ø§Ø³Øª).", Toast.LENGTH_LONG).show()
        }
    }

    private fun setupListeners() {
        getSendButton().setOnClickListener {
            sendMessage()
        }
        
        // ØªÙ†Ø¸ÛŒÙ… VoiceRecorderView ÛŒØ§ VoiceActionButton
        try {
            voiceRecorderView = getVoiceButton() as? VoiceRecorderView
            if (voiceRecorderView != null) {
                voiceRecorderView!!.setListener(object : VoiceRecorderView.VoiceRecorderListener {
                    override fun onRecordingStarted() {
                        checkAudioPermissionAndStartRecording()
                    }
                    
                    override fun onRecordingCompleted(audioFile: File, durationMs: Long) {
                        transcribeAudio(audioFile)
                    }
                    
                    override fun onRecordingCancelled() {
                        Toast.makeText(this@BaseChatActivity, "âŒ Ø¶Ø¨Ø· Ù„ØºÙˆ Ø´Ø¯", Toast.LENGTH_SHORT).show()
                    }
                    
                    override fun onAmplitudeChanged(amplitude: Int) {
                        // Ù†Ù…Ø§ÛŒØ´ Ø´Ø¯Øª ØµØ¯Ø§
                    }
                })
                android.util.Log.d("BaseChatActivity", "VoiceRecorderView initialized successfully")
            } else {
                android.util.Log.w("BaseChatActivity", "VoiceRecorderView not found, voice recording disabled")
            }
        } catch (e: Exception) {
            android.util.Log.e("BaseChatActivity", "Error initializing VoiceRecorderView", e)
        }

        // If a unified VoiceActionButton exists in the layout, wire it up so
        // chat activities automatically benefit from the unified recorder.
        try {
            val vab = findViewById<com.persianai.assistant.ui.VoiceActionButton?>(
                resources.getIdentifier("voiceActionButton", "id", packageName)
            )
            if (vab != null) {
                vab.setListener(object : com.persianai.assistant.ui.VoiceActionButton.Listener {
                    override fun onRecordingStarted() {
                        onVoiceRecordingStarted()
                    }

                    override fun onRecordingCompleted(audioFile: File, durationMs: Long) {
                        transcribeAudio(audioFile)
                    }

                    override fun onTranscript(text: String) {
                        try {
                            getMessageInput().setText(text)
                            sendMessage()
                        } catch (_: Exception) { }
                    }

                    override fun onRecordingError(error: String) {
                        onVoiceRecordingError(error)
                    }
                })
                android.util.Log.d("BaseChatActivity", "VoiceActionButton wired")
            }
        } catch (e: Exception) {
            android.util.Log.w("BaseChatActivity", "VoiceActionButton not present or wiring failed", e)
        }
    }

    protected fun sendMessage() {
        val text = getMessageInput().text.toString().trim()
        if (text.isEmpty()) return

        val userMessage = ChatMessage(role = MessageRole.USER, content = text, timestamp = System.currentTimeMillis())
        addMessage(userMessage)
        getMessageInput().text?.clear()

        getSendButton().isEnabled = false

        lifecycleScope.launch {
            try {
                val response = handleRequest(text)
                val aiMessage = ChatMessage(role = MessageRole.ASSISTANT, content = response, timestamp = System.currentTimeMillis())
                addMessage(aiMessage)
            } catch (e: Exception) {
                val errorMessage = ChatMessage(role = MessageRole.ASSISTANT, content = "âŒ Ø®Ø·Ø§: ${e.message}", timestamp = System.currentTimeMillis(), isError = true)
                addMessage(errorMessage)
            } finally {
                getSendButton().isEnabled = true
            }
        }
    }

    protected open suspend fun handleRequest(text: String): String = withContext(Dispatchers.IO) {
        val workingMode = prefsManager.getWorkingMode()
        val onlinePreferred = shouldUseOnlinePriority()

        // Ø­Ø§Ù„Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶: Ø¢ÙÙ„Ø§ÛŒÙ† TinyLlama
        if (!onlinePreferred || workingMode == PreferencesManager.WorkingMode.OFFLINE) {
            return@withContext offlineRespond(text)
        }

        if (aiClient == null) {
            return@withContext offlineRespond(text)
        }

        val model = chooseBestModel(prefsManager.getAPIKeys(), prefsManager.getProviderPreference())
        return@withContext try {
            currentModel = model
            val response = aiClient!!.sendMessage(
                model,
                messages,
                getSystemPrompt() + "\n\nÙ¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø±: " + text
            )
            response.content
        } catch (e: Exception) {
            android.util.Log.w("BaseChatActivity", "Online analysis failed: ${e.message}")
            offlineRespond(text)
        }
    }

    private fun offlineRespond(text: String): String {
        // ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ†ØªØ§Ø¬ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø² Ù…Ø¯Ù„ Ø¢ÙÙ„Ø§ÛŒÙ† (Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯)
        val modelPath = findOfflineModelPath()
        if (modelPath != null) {
            val prompt = buildString {
                append("Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± ÙØ§Ø±Ø³ÛŒ Ù‡Ø³ØªÛŒØ¯. Ù¾Ø§Ø³Ø® Ú©ÙˆØªØ§Ù‡ Ùˆ Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ø¯Ù‡.\n")
                append("Ú©Ø§Ø±Ø¨Ø±: ").append(text).append("\nØ¯Ø³ØªÛŒØ§Ø±:")
            }
            try {
                val generated = com.persianai.assistant.offline.LocalLlamaRunner.infer(modelPath, prompt, maxTokens = 96)
                if (!generated.isNullOrBlank()) {
                    return "ğŸŸ¢ Ù¾Ø§Ø³Ø® Ø¢ÙÙ„Ø§ÛŒÙ† (TinyLlama):\n$generated"
                }
            } catch (e: Exception) {
                android.util.Log.w("BaseChatActivity", "Local inference failed: ${e.message}")
            }
        }

        // Ø¯Ø± ØµÙˆØ±Øª Ù†Ø¨ÙˆØ¯ Ù…Ø¯Ù„ ÛŒØ§ Ø®Ø·Ø§ØŒ Ø®Ù„Ø§ØµÙ‡ Ø³Ø§Ø¯Ù‡
        val summary = if (text.length > 140) text.take(140) + "â€¦" else text
        return "ğŸŸ¢ Ù¾Ø§Ø³Ø® Ø¢ÙÙ„Ø§ÛŒÙ† (placeholder):\n$summary"
    }

    /**
     * ÛŒØ§ÙØªÙ† Ù…Ø³ÛŒØ± Ù…Ø¯Ù„ tinyllama Ø¯Ø§Ù†Ù„ÙˆØ¯â€ŒØ´Ø¯Ù‡ (Ø¯Ø³ØªÛŒ ÛŒØ§ Ø§Ø² Ø·Ø±ÛŒÙ‚ OfflineModelManager)
     */
    private fun findOfflineModelPath(): String? {
        return try {
            val manager = com.persianai.assistant.models.OfflineModelManager(this)
            val list = manager.getDownloadedModels()
            // Ø§ÙˆÙ„ TinyLlama
            list.firstOrNull { it.first.name.contains("TinyLlama", ignoreCase = true) }?.second
                ?: list.firstOrNull()?.second
        } catch (e: Exception) {
            android.util.Log.w("BaseChatActivity", "findOfflineModelPath failed: ${e.message}")
            null
        }
    }

    protected open fun shouldUseOnlinePriority(): Boolean = false

    protected open fun getSystemPrompt(): String {
        return "Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯ ÙØ§Ø±Ø³ÛŒ Ù‡Ø³ØªÛŒØ¯."
    }

    protected fun addMessage(message: ChatMessage) {
        messages.add(message)
        chatAdapter.notifyItemInserted(messages.size - 1)
        getRecyclerView().smoothScrollToPosition(messages.size - 1)
        if (message.role == MessageRole.ASSISTANT && !message.isError) {
            ttsHelper.speak(message.content)
        }
    }

    private fun checkAudioPermissionAndStartRecording() {
        val permissions = arrayOf(Manifest.permission.RECORD_AUDIO)
        val missingPermissions = permissions.filter {
            ContextCompat.checkSelfPermission(this, it) != PackageManager.PERMISSION_GRANTED
        }
        
        if (missingPermissions.isNotEmpty()) {
            ActivityCompat.requestPermissions(this, missingPermissions.toTypedArray(), REQUEST_RECORD_AUDIO)
        }
    }

    protected fun transcribeAudio(audioFile: File) {
        lifecycleScope.launch {
            try {
                // Ø¯Ø± Ø­Ø§Ù„Øª Ø¬Ø¯ÛŒØ¯: Ø¨Ø¯ÙˆÙ† Ù¾Ù†Ø¬Ø±Ù‡ Ú¯ÙˆÚ¯Ù„ØŒ ÙÙ‚Ø· ØªÙ„Ø§Ø´ Ø¢Ù†Ù„Ø§ÛŒÙ† (Ø¯Ø± ØµÙˆØ±Øª ÙØ¹Ø§Ù„ Ø¨ÙˆØ¯Ù†) ÙˆÚ¯Ø±Ù†Ù‡ Ù¾ÛŒØ§Ù… Ø¢ÙÙ„Ø§ÛŒÙ†
                val transcribedText = aiClient?.transcribeAudio(audioFile.absolutePath)
                    ?.takeIf { !it.isNullOrBlank() }
                    ?: transcribeWithHuggingFace(audioFile)
                
                if (!transcribedText.isNullOrEmpty()) {
                    getMessageInput().setText(transcribedText)
                    Toast.makeText(this@BaseChatActivity, "âœ… ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† ØªØ¨Ø¯ÛŒÙ„ Ø´Ø¯", Toast.LENGTH_SHORT).show()
                    sendMessage()
                    return@launch
                }
                
                Toast.makeText(this@BaseChatActivity, "ğŸ™ï¸ ÙØ§ÛŒÙ„ Ø¶Ø¨Ø·â€ŒØ´Ø¯Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ (Ø¢ÙÙ„Ø§ÛŒÙ†). Ù…ØªÙ† Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.", Toast.LENGTH_SHORT).show()
            } catch (e: Exception) {
                android.util.Log.e("BaseChatActivity", "Transcription failed: ${e.message}", e)
                Toast.makeText(this@BaseChatActivity, "ğŸ™ï¸ Ø¶Ø¨Ø· Ø¢ÙÙ„Ø§ÛŒÙ† Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯ (ØªØ¨Ø¯ÛŒÙ„ Ù†Ø§Ù…ÙˆÙÙ‚)", Toast.LENGTH_SHORT).show()
            }
        }
    }

    override fun onRequestPermissionsResult(requestCode: Int, permissions: Array<String>, grantResults: IntArray) {
        super.onRequestPermissionsResult(requestCode, permissions, grantResults)
        if (requestCode == REQUEST_RECORD_AUDIO) {
            if (grantResults.isEmpty() || grantResults.any { it != PackageManager.PERMISSION_GRANTED }) {
                Toast.makeText(this, "âš ï¸ Ù…Ø¬ÙˆØ² Ø¶Ø¨Ø· ØµÙˆØª Ù„Ø§Ø²Ù… Ø§Ø³Øª", Toast.LENGTH_SHORT).show()
            }
        }
    }

    override fun onDestroy() {
        super.onDestroy()
        ttsHelper.shutdown()
        speechRecognizer.destroy()
        voiceHelper.cancelRecording()
    }
    
    // ===== Voice Recording Setup =====
    
    protected open fun setupVoiceRecording() {
        voiceHelper.setListener(object : VoiceRecordingHelper.RecordingListener {
            override fun onRecordingStarted() {
                Log.d("BaseChatActivity", "Recording started")
                onVoiceRecordingStarted()
            }
            
            override fun onRecordingCompleted(audioFile: File, durationMs: Long) {
                Log.d("BaseChatActivity", "Recording completed: ${audioFile.absolutePath}, Duration: ${durationMs}ms")
                onVoiceRecordingCompleted(audioFile, durationMs)
            }
            
            override fun onRecordingCancelled() {
                Log.d("BaseChatActivity", "Recording cancelled")
                onVoiceRecordingCancelled()
            }
            
            override fun onRecordingError(error: String) {
                Log.e("BaseChatActivity", "Recording error: $error")
                onVoiceRecordingError(error)
            }
        })
    }
    
    protected open fun onVoiceRecordingStarted() {
        Log.d("BaseChatActivity", "Voice recording started")
    }
    
    protected open fun onVoiceRecordingCompleted(audioFile: File, durationMs: Long) {
        Log.d("BaseChatActivity", "Voice recording completed")
        // Ù¾Ø³ Ø§Ø² Ø§ØªÙ…Ø§Ù… Ø¶Ø¨Ø·: ØªØ¨Ø¯ÛŒÙ„ Ú¯ÙØªØ§Ø± Ø¨Ù‡ Ù…ØªÙ† Ùˆ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ Ú†Øª
        transcribeAudio(audioFile)
    }
    
    protected open fun onVoiceRecordingCancelled() {
        Log.d("BaseChatActivity", "Voice recording cancelled")
    }
    
    protected open fun onVoiceRecordingError(error: String) {
        Log.e("BaseChatActivity", "Voice recording error: $error")
        Toast.makeText(this, "Ø®Ø·Ø§: $error", Toast.LENGTH_SHORT).show()
    }
    
    protected fun startVoiceRecording() {
        if (ContextCompat.checkSelfPermission(this, Manifest.permission.RECORD_AUDIO)
            == PackageManager.PERMISSION_GRANTED
        ) {
            voiceHelper.startRecording()
        } else {
            ActivityCompat.requestPermissions(
                this,
                arrayOf(Manifest.permission.RECORD_AUDIO),
                REQUEST_RECORD_AUDIO
            )
        }
    }
    
    protected fun stopVoiceRecording() {
        voiceHelper.stopRecording()
    }
    
    protected fun cancelVoiceRecording() {
        voiceHelper.cancelRecording()
    }
}
