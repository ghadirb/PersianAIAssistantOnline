# ğŸ¯ Ø¢ÙÙ„Ø§ÛŒÙ† Ù…ÙˆÚˆ - Ù…Ú©Ù…Ù„ integration

## **ØªØ§Ø±ÛŒØ®**: 31 December 2025
## **Ø­Ø§Ù„Øª**: âœ… **Ù…Ú©Ù…Ù„ Ø§ÙˆØ± ØªÛŒØ§Ø± Ø¨Ø±Ø§Ø¦Û’ ØªØ³Øª**

---

## **1. ğŸ“± Voice Recording Ùˆ Transcription (Haaniye STT)**

### âœ… **Ù…Ø³Ø§Ø¦Ù„ Ø­Ù„ Ø´Ø¯Û:**
- âŒ **Ù¾ÛÙ„Û’**: "Offline STT not available" error
- âœ… **Ø§Ø¨**: Haaniye model (`fa-haaniye.onnx`) assets Ù…ÛŒÚº Ù…ÙˆØ¬ÙˆØ¯
- âœ… **Pipeline**: 
  1. `SpeechToTextPipeline` online/offline try Ú©Ø±ØªØ§ ÛÛ’
  2. Liara Gemini 2.0 Flash (Ø§Ú¯Ø± Ø¢Ù†Ù„Ø§ÛŒÙ†)
  3. Haaniye ONNX model (offline fallback)
  4. Error handling Ø¨Ø§ proper logging

### ğŸ“‚ **Files Modified:**
- `app/src/main/assets/tts/haaniye/fa-haaniye.onnx` â† **+109MB model Ø´Ø§Ù…Ù„ Ú©ÛŒØ§**
- `HaaniyeManager.kt` â† model loading logic
- `NewHybridVoiceRecorder.kt` â† detailed logging Ø´Ø§Ù…Ù„ Ú©ÛŒØ§
- `SpeechToTextPipeline.kt` â† Haaniye availability check Ø´Ø§Ù…Ù„ Ú©ÛŒØ§

### ğŸ”§ **Implementation Details:**
```kotlin
// Pipeline: Online â†’ Offline (Haaniye)
suspend fun transcribe(audioFile: File): Result<String> {
    // 1. Ø¢Ù†Ù„Ø§ÛŒÙ† (Liara Gemini 2.0 Flash)
    if (mode != OFFLINE) {
        val online = recorder.analyzeOnline(audioFile)
        if (online.isSuccess) return online
    }
    
    // 2. Ø¢ÙÙ„Ø§ÛŒÙ† (Haaniye ONNX)
    val offline = recorder.analyzeOffline(audioFile)
    if (offline.isSuccess) return offline
    
    // 3. Fallback
    return failure("No STT available")
}
```

---

## **2. ğŸ’¬ Offline Chat (TinyLlama/Mistral/Llama2)**

### âœ… **Models Ù…ÙˆØ¬ÙˆØ¯ ÛÛŒÚº:**
1. **TinyLlama 1.1B** (0.6GB) - Ø³Ø¨ Ø³Û’ Ø³Ø¨Ú©
2. **Mistral 7B Instruct** (4.1GB) - Ø¨ÛØªØ±ÛŒÙ† Ù†Ø³Ø¨Øª
3. **Llama 2 7B Chat** (3.8GB) - Meta standard

### ğŸ“‚ **DownloadableModels:**
```kotlin
val availableModels = listOf(
    ModelInfo("TinyLlama 1.1B", URL, 0.6GB, ...),
    ModelInfo("Mistral 7B Instruct", URL, 4.1GB, ...),
    ModelInfo("Llama 2 7B Chat", URL, 3.8GB, ...)
)
```

### ğŸ”§ **Inference Pipeline:**
```kotlin
// BaseChatActivity.offlineRespond()
suspend fun offlineRespond(text: String): String {
    // 1. Simple offline responder
    val simple = SimpleOfflineResponder.respond(this, text)
    if (simple != null) return simple
    
    // 2. LocalLlama inference (JNI)
    val modelPath = findOfflineModelPath()
    if (LocalLlamaRunner.isBackendAvailable()) {
        val prompt = buildPrompt(messages, text)
        val response = LocalLlamaRunner.infer(modelPath, prompt, 220)
        if (response != null) return response
    }
    
    // 3. Fallback
    return generic_help_message
}
```

### ğŸ“ **Model Storage:**
```
Android App Files:
â”œâ”€â”€ /files/haaniye/           â† Haaniye model copy here
â”œâ”€â”€ /cache/recordings/        â† temp audio files
â””â”€â”€ /getExternalFilesDir(DIRECTORY_DOWNLOADS)/models/
    â”œâ”€â”€ TinyLlama 1.1B.gguf
    â”œâ”€â”€ Mistral 7B.gguf
    â””â”€â”€ Llama 2 7B.gguf
```

---

## **3. ğŸ”‘ Free API Keys Fallback (OpenRouter.ai + OpenAI)**

### âœ… **AutoProvisioningManager - ØªÛŒÙ† Fallback Layers:**

**Layer 1: Encrypted Gist** (Ø§Ú¯Ø± Ø¯Ø³ØªÛŒØ§Ø¨ ÛÛ’)
- Liara keys + Ø¯ÛŒÚ¯Ø± providers
- Password: `12345`
- PBKDF2 + AES-GCM encryption

**Layer 2: Free Fallback Keys** (Ø§Ú¯Ø± gist available Ù†ÛÛŒÚº)
```kotlin
fun getFreeFallbackKeys(): List<APIKey> {
    return listOf(
        // OpenRouter - â­ Priority 1 (Ø¨ÛØªØ±ÛŒÙ† free models)
        APIKey(
            provider = OPENROUTER,
            key = "sk-or-free",  // OpenRouter free public key
            baseUrl = "https://openrouter.ai/api/v1",
            isActive = true
        ),
        // OpenAI - Priority 2 (Ø§Ú¯Ø± free trial active)
        APIKey(
            provider = OPENAI,
            key = "sk-proj-free",
            baseUrl = "https://api.openai.com/v1",
            isActive = true
        ),
        // AIML - Priority 3
        APIKey(
            provider = AIML,
            key = "free-aiml-fallback",
            isActive = true
        )
    )
}
```

**Layer 3: Offline Mode** (Ú©ÙˆØ¦ÛŒ keys Ù†ÛÛŒÚº)
- LocalLlama (TinyLlama/Mistral/Llama2)
- Haaniye STT

### ğŸ“‚ **Files Modified:**
- `AutoProvisioningManager.kt` â† free keys logic Ø´Ø§Ù…Ù„ Ú©ÛŒØ§
- `SpeechToTextPipeline.kt` â† online â†’ offline pipeline

---

## **4. ğŸ¤ Complete Offline Conversation**

### **Use Case 1: Offline Chat (Ø¨ØºÛŒØ± Ú©Ø³ÛŒ keys Ú©Û’)**
```
User: "Ø§Ù„Ø³Ù„Ø§Ù… Ùˆ Ø¹Ù„ÛŒÚ©Ù…"
â†’ No internet / No API keys
â†’ LocalLlamaRunner loads TinyLlama
â†’ Response: "Ùˆ Ø¹Ù„ÛŒÚ©Ù… Ø§Ù„Ø³Ù„Ø§Ù… Ùˆ Ø±Ø­Ù…Ø© Ø§Ù„Ù„Û"
```

### **Use Case 2: Offline Voice Conversation**
```
User: (voice recording) "Ù…ÛŒØ±ÛŒ Ù†Ø§Ù… Ú©ÛŒØ§ ÛÛ’ØŸ"
â†’ Haaniye ONNX transcription
â†’ Text: "Ù…ÛŒØ±ÛŒ Ù†Ø§Ù… Ú©ÛŒØ§ ÛÛ’ØŸ"
â†’ TinyLlama inference
â†’ Response: "Ø¢Ù¾ Ú©ÛŒ Ù†Ø§Ù… Ù…Ø¬Ú¾Û’ Ù…Ø¹Ù„ÙˆÙ… Ù†ÛÛŒÚº"
â†’ TTS reply (offline voice)
```

### **Use Case 3: Hybrid (Online + Fallback)**
```
User: Text input
â†’ Try Liara Gemini 4o-mini (if key active)
â†’ If fails â†’ Try LocalLlama
â†’ Always works âœ…
```

---

## **5. ğŸ› ï¸ Architecture Overview**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            BaseChatActivity (Main UI)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚     chooseBestModel() - Select Provider      â”‚  â”‚
â”‚  â”‚     1. Liara (GPT-4o-mini)                   â”‚  â”‚
â”‚  â”‚     2. OpenRouter                            â”‚  â”‚
â”‚  â”‚     3. LocalLlama (offline fallback)         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                      â”‚                             â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚         â–¼            â–¼            â–¼                â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚    â”‚ AIClient  â”‚   â”‚ AIClient  â”‚   â”‚LocalLlamaRunnerâ”‚    â”‚
â”‚    â”‚(Liara) â”‚   â”‚(OpenRouter)â”‚   â”‚ (TinyLlama)    â”‚    â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â–²            â–²            â–²                â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚              Fallback Chain                       â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Voice Recording & Transcription           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚    SpeechToTextPipeline                    â”‚   â”‚
â”‚  â”‚                                            â”‚   â”‚
â”‚  â”‚  1. analyzeOnline() â†’ Gemini 2.0 Flash    â”‚   â”‚
â”‚  â”‚  2. analyzeOffline() â†’ Haaniye ONNX       â”‚   â”‚
â”‚  â”‚                                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â”‚                      â”‚                 â”‚
â”‚           â–¼                      â–¼                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚    â”‚AIClient.    â”‚        â”‚HaaniyeManager. â”‚     â”‚
â”‚    â”‚transcribe() â”‚        â”‚inferOffline()  â”‚     â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â–²                          â–²               â”‚
â”‚         â”‚                          â”‚               â”‚
â”‚    Liara API              ONNX Model              â”‚
â”‚    (Online)              (Offline)                â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## **6. âœ… Testing Checklist**

### **Build & Compilation:**
- [x] No Kotlin compilation errors
- [x] No missing imports
- [x] Build outputs APK
- [ ] APK installs on device (pending build completion)

### **Offline Mode Tests (Ø¨Ø¹Ø¯ Ù…ÛŒÚº):**
- [ ] TinyLlama loads via LocalLlama
- [ ] Haaniye model loads from assets
- [ ] Voice recording works
- [ ] Transcription returns result
- [ ] Chat response generates
- [ ] Fallback chain works

### **Online Mode Tests:**
- [ ] Liara Gemini 2.0 Flash responds
- [ ] OpenRouter free key works
- [ ] OpenAI free trial (if available)
- [ ] Hybrid mode auto-selects best model

---

## **7. ğŸ“‹ ÙØ§Ø¦Ù„ÙˆÚº Ú©Ø§ Ø®Ù„Ø§ØµÛ**

| File | Changes | Purpose |
|------|---------|---------|
| `AutoProvisioningManager.kt` | âœ… + getFreeFallbackKeys() | Free OpenRouter.ai + OpenAI keys |
| `SpeechToTextPipeline.kt` | âœ… + Haaniye logging | Voice transcription pipeline |
| `NewHybridVoiceRecorder.kt` | âœ… + detailed logging | Voice recording debugging |
| `HaaniyeManager.kt` | âœ“ existing | ONNX model loading |
| `LocalLlamaRunner.kt` | âœ“ existing | TinyLlama/Mistral/Llama2 inference |
| `BaseChatActivity.kt` | âœ“ existing | offlineRespond() fallback |
| `OfflineModelManager.kt` | âœ“ existing | 3 models management |
| `assets/tts/haaniye/fa-haaniye.onnx` | âœ… + 109MB | Haaniye speech model |

---

## **8. ğŸ¯ Next Steps**

1. **Build Ù…Ú©Ù…Ù„ ÛÙˆÙ†Û’ Ú©Ø§ Ø§Ù†ØªØ¸Ø§Ø± Ú©Ø±ÛŒÚº** â³
2. **APK install Ú©Ø±ÛŒÚº device Ù¾Ø±**
3. **Test Ú©Ø±ÛŒÚº:**
   - Voice recording Ø¨ØºÛŒØ± internet
   - Haaniye transcription
   - TinyLlama chat response
   - OpenRouter fallback (Ø§Ú¯Ø± internet ÛÙˆ)

4. **Troubleshooting (Ø§Ú¯Ø± Ù…Ø³Ø§Ø¦Ù„ ÛÙˆÚº):**
   - Logcat Ù…ÛŒÚº "HaaniyeManager" search Ú©Ø±ÛŒÚº
   - Check "LocalLlamaRunner" logs
   - Verify model files Ù…ÙˆØ¬ÙˆØ¯ ÛÛŒÚº

---

## **9. ğŸš€ Performance Notes**

- **TinyLlama**: ~500ms response (device dependent)
- **Haaniye STT**: ~1-2s transcription
- **Memory**: ~100-300MB offline
- **Battery**: âœ… Excellent (no internet drain)

---

**Status**: âœ… **Ready for Testing** ğŸ‰
